{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Job Matching System"
      ],
      "metadata": {
        "id": "b_QLYRz0Z_Rj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Job Description System"
      ],
      "metadata": {
        "id": "FSNfKr6YO3ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-pdf docx spacy\n"
      ],
      "metadata": {
        "id": "7I0-QsyKPpPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b815479e-364b-48a8-b71d-d30fb1219620"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-pdf\n",
            "  Downloading python_pdf-0.40-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docx) (5.3.0)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.10/dist-packages (from docx) (11.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading python_pdf-0.40-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docx\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53892 sha256=09be87cfe0b13b2cebe9ee1886c9b2de26cb1100c68087e534181eaa835a69eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/f5/1d/e09ba2c1907a43a4146d1189ae4733ca1a3bfe27ee39507767\n",
            "Successfully built docx\n",
            "Installing collected packages: python-pdf, docx\n",
            "Successfully installed docx-0.2.4 python-pdf-0.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g-nYUBMsO00X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e66dfb-e4f9-44a1-b504-fd13c30a1327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'skills': [], 'experience': '0-1 years'}\n",
            "Looking for a Python developer with 0-1 years of experience. Skills: Python, Django, REST API.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "def extract_job_requirements(job_description):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(job_description)\n",
        "    skills = [ent.text for ent in doc.ents if ent.label_ == \"SKILL\"]\n",
        "    return {\n",
        "        \"skills\": skills,\n",
        "        \"experience\": \"0-1 years\" if \"0-1 years\" in job_description else \"Not mentioned\",\n",
        "    }\n",
        "\n",
        "job_description = \"Looking for a Python developer with 0-1 years of experience. Skills: Python, Django, REST API.\"\n",
        "parsed_job = extract_job_requirements(job_description)\n",
        "print(parsed_job)\n",
        "print(job_description)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resume Upload**"
      ],
      "metadata": {
        "id": "uup4q5Iv4jaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  #using this to upload 'candidate_resume.docx'\n"
      ],
      "metadata": {
        "id": "WMYGnnjiQP88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "9c40e767-b6e1-479c-9da0-26cf71138e23"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b0e60bff-9ea7-4c83-beaa-e3d9fef35542\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b0e60bff-9ea7-4c83-beaa-e3d9fef35542\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Adarsh_IITJ_Resume.docx to Adarsh_IITJ_Resume.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n"
      ],
      "metadata": {
        "id": "LxMnR7x-5cwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7b63a1-84f4-4ff7-c06d-14f6b59e0ff8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m204.8/244.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import re\n",
        "\n",
        "# Specifying the correct file path\n",
        "file_path = \"/content/Adarsh_IITJ_Resume.docx\"\n",
        "\n",
        "def extract_resume_details(file_path):\n",
        "    document = Document(file_path)\n",
        "    text = \"\\n\".join([para.text for para in document.paragraphs])\n",
        "    skills = re.findall(r\"(Python|Django|REST API|Machine Learning)\", text, re.IGNORECASE)\n",
        "    return {\n",
        "        \"name\": re.search(r\"Adarsh:\\s*(.*)\", text).group(1) if re.search(r\"Adarsh:\\s*(.*)\", text) else \"Adarsh\",\n",
        "        \"skills\": set(skills),\n",
        "    }\n",
        "\n",
        "resume_details = extract_resume_details(file_path)\n",
        "print(resume_details)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q7EMXzVEO6Et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0872bf5e-78a3-4645-f554-1c64054eb3b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Adarsh', 'skills': {'Machine Learning', 'Django', 'Python'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract key job requirements such as skills, qualifications, years of experience, and responsibilities from each description.**"
      ],
      "metadata": {
        "id": "5RJ_R0YyXHpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "job_description_content = {\n",
        "    \"title\": \"Data Scientist\",\n",
        "    \"skills\": [\"Python\", \"Machine Learning\", \"Django\", \"Data Analysis\"],\n",
        "    \"experience_required\": \"2-3 years\",\n",
        "    \"qualifications\": \"Bachelor's degree in Computer Science or related field\"\n",
        "}\n",
        "\n",
        "file_path = \"/content/Adarsh_IITJ_Resume.docx\"\n",
        "doc = Document()\n",
        "doc.add_heading(\"Job Description\", level=1)\n",
        "\n",
        "for key, value in job_description_content.items():\n",
        "    doc.add_heading(key.capitalize(), level=2)\n",
        "    if isinstance(value, list):\n",
        "        for item in value:\n",
        "            doc.add_paragraph(f\"- {item}\")\n",
        "    else:\n",
        "        doc.add_paragraph(value)\n",
        "\n",
        "doc.save(file_path)\n",
        "print(f\"Job description Word file created successfully at {file_path}.\")\n"
      ],
      "metadata": {
        "id": "b1LZimOl7Uej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973aa7f4-0007-4c84-d994-400b2dfc6edb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job description Word file created successfully at /content/Adarsh_IITJ_Resume.docx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Key Information\n",
        "Use NLP techniques to extract key information like skills, experience, qualifications, and education.\n"
      ],
      "metadata": {
        "id": "QDn98csBQ-86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Defining Skills List (Job Description)\n",
        "job_description_skills = [\"Python\", \"Machine Learning\", \"Django\", \"SQL\", \"NLP\"]\n",
        "\n",
        "resume_text = \"\"\"\n",
        "I am a Data Scientist with experience in Python, Machine Learning, SQL, and working with NLP tasks.\n",
        "\"\"\"\n",
        "\n",
        "# Preprocessing text and extracting skills\n",
        "def extract_skills(text, skill_set):\n",
        "    skills_found = [skill for skill in skill_set if skill.lower() in text.lower()]\n",
        "    return skills_found\n",
        "\n",
        "\n",
        "resume_skills = extract_skills(resume_text, job_description_skills)\n",
        "\n",
        "# Comparing the skills: Finding common, missing, and extra skills\n",
        "common_skills = set(resume_skills).intersection(set(job_description_skills))\n",
        "missing_skills = set(job_description_skills) - set(resume_skills)\n",
        "extra_skills = set(resume_skills) - set(job_description_skills)\n",
        "\n",
        "print(\"Resume Skills:\", resume_skills)\n",
        "print(\"Common Skills:\", common_skills)\n",
        "print(\"Missing Skills:\", missing_skills)\n",
        "print(\"Extra Skills:\", extra_skills)\n",
        "\n"
      ],
      "metadata": {
        "id": "IC-sKS34SFR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9b0e6b-c295-4aee-a12c-482f1877a3df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Skills: ['Python', 'Machine Learning', 'SQL', 'NLP']\n",
            "Common Skills: {'Machine Learning', 'Python', 'SQL', 'NLP'}\n",
            "Missing Skills: {'Django'}\n",
            "Extra Skills: set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def extract_job_description_details(file_path):\n",
        "    \"\"\"\n",
        "    Extracts text from a .docx file and processes it to return job-related details.\n",
        "\n",
        "    :param file_path: Path to the .docx file.\n",
        "    :return: Extracted job description details as text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "\n",
        "        doc = Document(file_path)\n",
        "      s\n",
        "        job_details = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "        return job_details\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Usage\n",
        "job_details = extract_job_description_details(\"/content/Adarsh_IITJ_Resume.docx\")\n",
        "print(job_details)\n"
      ],
      "metadata": {
        "id": "QhnR47gBT4sG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef43049-1fcf-49b1-f380-1785ca17990f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job Description\n",
            "Title\n",
            "Data Scientist\n",
            "Skills\n",
            "- Python\n",
            "- Machine Learning\n",
            "- Django\n",
            "- Data Analysis\n",
            "Experience_required\n",
            "2-3 years\n",
            "Qualifications\n",
            "Bachelor's degree in Computer Science or related field\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Extract Text from Resumes**"
      ],
      "metadata": {
        "id": "uyv1Rkci8BLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Profile-Job Matching:**\n",
        "    - Automatically compare the uploaded resume with the job descriptions and identify the **best matching roles** based on key factors such as skills, experience, and qualifications. **bold text**"
      ],
      "metadata": {
        "id": "WmQefHHBPO4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract text from resume  **"
      ],
      "metadata": {
        "id": "QGSExp5sOeiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from docx import Document\n",
        "\n",
        "\n",
        "def upload_docx():\n",
        "    print(\"Upload your .docx file:\")\n",
        "    uploaded = files.upload()\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "    return file_name\n",
        "\n",
        " #Extracting Text from the Uploaded .docx File\n",
        "def extract_text_from_docx(file_path):\n",
        "    document = Document(file_path)\n",
        "    text = \"\\n\".join([para.text for para in document.paragraphs])\n",
        "    return text\n",
        "\n",
        "resume_file = upload_docx()\n",
        "resume_text = extract_text_from_docx(resume_file)\n",
        "\n",
        "\n",
        "print(\"\\n--- Extracted Resume Text ---\\n\")\n",
        "print(resume_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wxp__l0Lt1WC",
        "outputId": "b9332c74-b451-4531-9846-dac76d4a508e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your .docx file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b78eb74d-116b-4f4f-82f9-b809bf8514ff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b78eb74d-116b-4f4f-82f9-b809bf8514ff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Adarsh_IITJ_Resume.docx to Adarsh_IITJ_Resume (2).docx\n",
            "\n",
            "--- Extracted Resume Text ---\n",
            "\n",
            "Adarsh Kumar\n",
            "IIT Jodhpur, Rajasthan 342026\n",
            "+91-8210306799\tadarshkumariitj@gmail.com\tLinkedIn\tGitHub\tCodeforces\tLeetCode\n",
            "Education\n",
            "\n",
            "Indian Institute of Technology, Jodhpur\tDec 2021 – May 2025\n",
            "(BTech in Biotechnology(Major -artificial intelligence and data science))\tJodhpur, Rajasthan\n",
            "Relevant Coursework\n",
            "\n",
            "Data Structures\n",
            "Machine Learning\n",
            "Experience\n",
            "Deep learning\n",
            "Computational biology\n",
            "Probability Statistics\n",
            "Intro to CS and OOPS\n",
            "Corporate Finance I\n",
            "Trends in FinTech\n",
            "\n",
            "\n",
            "MoveInSync\tMay 2024 – July 2024\n",
            "Software Developer\tBengaluru, India\n",
            "Developed a Traffic Delay-Based Accessibility Index for metropolitan cities, utilizing GeoJSON and Uber H3 API\n",
            "for visualizations. Optimized data processing by 12x using Parquet files.\n",
            "Designed and implemented a Monitoring Dashboard for ETL pipeline jobs, achieving **zero-cost monitoring** and enabling data-driven decision-making.\n",
            "LazyApply\tmarch 2023 – July 2023\n",
            "Data Analyst\tBengaluru, India\n",
            "Performed in-depth data analysis using Python and SQL, providing actionable insights to support business decisions.\n",
            "Developed interactive dashboards using Tableau and Power BI, improving cross-functional data accessibility and collab-\n",
            "oration.\n",
            "Projects / Open-Source\n",
            "AppraiseMe (Full Stack Project)\n",
            "Developed a social platform where users can create profiles and receive reviews on their soft skills.\n",
            "Implemented features like profile creation, adding work experience, basic details, and profile images.\n",
            "Integrated functionality for reviewing profiles using sliders and text descriptions, with search functionality to explore other user profiles.\n",
            "Tech Stack: React, Django, HTML, CSS, JavaScript, and Python.\n",
            "Chatbot Design using Deep Neural Networks\n",
            "Developed a chatbot leveraging Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM)models, achieving 85% response accuracy.\n",
            "Designed the chatbot to handle diverse queries effectively, improving user interaction through accurate text predictions.\n",
            "Bike Sharing Demand Prediction\n",
            "Implemented regression models to predict bike rental demand based on features like weather and time, achieving a\n",
            "Mean Squared Error (MSE)of 3.47 and an R2 score of 0.92.\n",
            "Preprocessed data to improve model accuracy, ensuring robust predictions for business use.\n",
            "\n",
            "Technical Skills\n",
            "Data Analytics & Optimization: Advanced Excel, SQL, Tableau, Power BI\n",
            "Programming Languages: Python, C, C++\n",
            "Libraries/Frameworks: Scikit-Learn, NLTK, OpenCV, TensorFlow, Keras\n",
            "AI/ML Technologies: NLP, Image Recognition, Graph Neural Networks, Time Series Analysis\n",
            "Statistical Analysis: Probability, Statistics, and Data Modeling\n",
            "Achievements\n",
            "Winner - TechFest, IIT Bombay (Dec 2022): Secured 1st place in a competitive technical fest.\n",
            "The certificate above verifies that Adarsh Kumar has successfully completed the course Java Programming. Certificate Link: https://www.mygreatlearning.com/certificate/INVEVWNG\n",
            "Positions of Responsibility\n",
            "Joint Secretary - FrameX, IIT Jodhpur 2022 – 2023\n",
            "Student Guide - IIT Jodhpur 2022 – 2023\n",
            "Member @ Quiz Society IITJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Match Analytics & Justification:**"
      ],
      "metadata": {
        "id": "jVxbigUTTjz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Skill match**\n",
        "- **Experience match**\n",
        "- **Education fit**\n",
        "- **Technological fit**"
      ],
      "metadata": {
        "id": "wkx7FE-CTrum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sample job description and resume\n",
        "job_description = {\n",
        "    \"title\": \"Data Scientist\",\n",
        "    \"skills\": [\"Python\", \"Machine Learning\", \"Django\", \"SQL\"],\n",
        "    \"experience_required\": \"2-3 years\",\n",
        "    \"qualifications\": [\"Bachelor's degree in Computer Science\", \"Data Science Certification\"],\n",
        "    \"technologies\": [\"TensorFlow\", \"Scikit-Learn\"]\n",
        "}\n",
        "\n",
        "resume_text = \"\"\"\n",
        "I am a Data Scientist with 3 years of experience, skilled in Python, Machine Learning, SQL, and Django.\n",
        "I hold a Bachelor's degree in Computer Science and a Data Science Certification.\n",
        "I have experience with TensorFlow and Scikit-Learn.\n",
        "\"\"\"\n",
        "\n",
        "# Extracting skills\n",
        "def extract_skills(text, skills):\n",
        "    return [skill for skill in skills if skill.lower() in text.lower()]\n",
        "\n",
        "# Extracting experience\n",
        "def extract_experience(text):\n",
        "    match = re.search(r\"(\\d+)\\s*years\", text)\n",
        "    return int(match.group(1)) if match else 0\n",
        "\n",
        "# Extracting qualifications\n",
        "def extract_qualifications(text, qualifications):\n",
        "    return [qual for qual in qualifications if qual.lower() in text.lower()]\n",
        "\n",
        "# Extracting technologies\n",
        "def extract_technologies(text, technologies):\n",
        "    return [tech for tech in technologies if tech.lower() in text.lower()]\n",
        "\n",
        "# Comparing the skill match percentage\n",
        "def skill_match_percentage(resume_skills, job_skills):\n",
        "    common_skills = set(resume_skills).intersection(set(job_skills))\n",
        "    return (len(common_skills) / len(job_skills)) * 100\n",
        "\n",
        "# Matching analytics\n",
        "def match_analytics(resume_text, job_description):\n",
        "    resume_skills = extract_skills(resume_text, job_description[\"skills\"])\n",
        "    resume_experience = extract_experience(resume_text)\n",
        "    resume_qualifications = extract_qualifications(resume_text, job_description[\"qualifications\"])\n",
        "    resume_technologies = extract_technologies(resume_text, job_description[\"technologies\"])\n",
        "\n",
        "    # Skill match\n",
        "    skills_match = skill_match_percentage(resume_skills, job_description[\"skills\"])\n",
        "\n",
        "    # Experience match\n",
        "    experience_match = job_description[\"experience_required\"] in f\"{resume_experience} years\"\n",
        "\n",
        "    # Education fit\n",
        "    education_fit = any(qual in resume_qualifications for qual in job_description[\"qualifications\"])\n",
        "\n",
        "    # Technological fit\n",
        "    tech_fit = len(resume_technologies) > 0\n",
        "\n",
        "\n",
        "    justification = {\n",
        "        \"Skills Match\": f\"{skills_match}% of required skills matched.\",\n",
        "        \"Experience Match\": \"Experience matches the job requirements.\" if experience_match else \"Experience does not match.\",\n",
        "        \"Education Fit\": \"Education qualifications match.\" if education_fit else \"Education qualifications do not match.\",\n",
        "        \"Technological Fit\": \"Technologies match.\" if tech_fit else \"Technologies do not match.\"\n",
        "    }\n",
        "\n",
        "    return justification\n",
        "\n",
        "\n",
        "analytics_result = match_analytics(resume_text, job_description)\n",
        "\n",
        "for key, value in analytics_result.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "id": "UTmO1hCLTjnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55eef0d4-6a2a-4dbe-8995-85d4c767a5b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skills Match: 100.0% of required skills matched.\n",
            "Experience Match: Experience does not match.\n",
            "Education Fit: Education qualifications match.\n",
            "Technological Fit: Technologies match.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting and Comparing Qualifications**"
      ],
      "metadata": {
        "id": "NhDdUqoUTG9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy python-Levenshtein\n"
      ],
      "metadata": {
        "id": "Gj584aKUR-Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601770b8-68dd-48d1-ce42-867c34e17d36"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.26.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 fuzzywuzzy-0.18.0 python-Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to extracting qualifications (degrees or certifications)\n",
        "def extract_qualifications(text):\n",
        "    qualifications = [\"bachelor's degree\", \"master's degree\", \"phd\", \"certification\"]\n",
        "    found_qualifications = [qual for qual in qualifications if qual in text.lower()]\n",
        "    return found_qualifications\n",
        "\n",
        "\n",
        "resume_qualifications = \"\"\"\n",
        "I have a Bachelor's degree in Computer Science. I also hold a certification in Data Science.\n",
        "\"\"\"\n",
        "\n",
        "job_description = {\n",
        "    \"title\": \"Data Scientist\",\n",
        "    \"qualifications\": [\"bachelor's degree\", \"master's degree\", \"certification in Data Science\"]\n",
        "}\n",
        "\n",
        "# Extracting Qualifications from both resume and job description\n",
        "resume_qualifications_extracted = extract_qualifications(resume_qualifications)\n",
        "job_qualifications_required = job_qualifications\n",
        "\n",
        "# Comparing Qualifications\n",
        "def compare_qualifications(resume_quals, job_quals):\n",
        "    missing_quals = set(job_quals) - set(resume_quals)\n",
        "    if not missing_quals:\n",
        "        return \"Qualifications match the requirements.\"\n",
        "    else:\n",
        "        return f\"Missing qualifications: {', '.join(missing_quals)}\"\n",
        "\n",
        "qualification_comparison = compare_qualifications(resume_qualifications_extracted, job_qualifications_required)\n",
        "print(\"Qualification Comparison:\", qualification_comparison)\n"
      ],
      "metadata": {
        "id": "rmqdCxSsQ-s6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50a7a02-4242-462e-c216-f9fc8fa1a8b1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qualification Comparison: Missing qualifications: certification in Data Science, master's degree\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Interview Analysis Module**"
      ],
      "metadata": {
        "id": "qSA_9Q0ZUC80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Provide a user-friendly interface for uploading interview videos, ensuring a smooth and intuitive experience."
      ],
      "metadata": {
        "id": "FJ5PTPv2Uacp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Flask"
      ],
      "metadata": {
        "id": "iUAEoQqNUaNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a822a734-d25c-4de2-f32b-7be6dfd4babc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uploading video**"
      ],
      "metadata": {
        "id": "WT-u_O82Xm7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Importing necessary modules\n",
        "from google.colab import files  # For uploading files\n",
        "import cv2  # For video processing\n",
        "\n",
        "# Step 2: Uploading video\n",
        "def upload_video():\n",
        "    uploaded = files.upload()  # Upload video file\n",
        "    video_file = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "    print(f\"Uploaded file: {video_file}\")\n",
        "    return video_file\n",
        "\n",
        "\n",
        "def process_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)  # Open video\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    print(f\"Video Information:\")\n",
        "    print(f\"Frames: {frame_count}, FPS: {fps}, Resolution: {width}x{height}\")\n",
        "\n",
        "    cap.release()  # Release the video object\n",
        "\n",
        "# Step 4: Download processed video\n",
        "def download_video(processed_video_path):\n",
        "    files.download(processed_video_path)  # Allow download of processed video\n",
        "\n",
        "# Step 5: Run the process\n",
        "video_file = upload_video()  # Upload the video\n",
        "video_path = f\"/content/{video_file}\"  # Path where Colab stores the video\n",
        "\n",
        "# Process the uploaded video\n",
        "process_video(video_path)\n",
        "\n",
        "\n",
        "# download_video(\"/content/processed_video.mp4\")"
      ],
      "metadata": {
        "id": "iJ8rDccYXuyy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "0a4a6df6-552b-4980-e5ec-b4ed93e9126e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e9e5ae7-0b79-43ba-97b2-b8777b7372f7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e9e5ae7-0b79-43ba-97b2-b8777b7372f7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Adarsh_kumar_IITJODHPUR.mp4 to Adarsh_kumar_IITJODHPUR.mp4\n",
            "Uploaded file: Adarsh_kumar_IITJODHPUR.mp4\n",
            "Video Information:\n",
            "Frames: 11769, FPS: 30.0, Resolution: 1280x720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Audio Extraction**"
      ],
      "metadata": {
        "id": "a131V1QP1svp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import moviepy.editor as mp\n",
        "\n",
        "def extract_audio(video_path, audio_path):\n",
        "    video = mp.VideoFileClip(video_path)\n",
        "    video.audio.write_audiofile(audio_path)\n",
        "    print(f\"Audio extracted and saved to {audio_path}\")\n",
        "\n",
        "audio_path = \"/content/interview_audio.wav\"\n",
        "extract_audio(video_path, audio_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPZl2_JE1o6t",
        "outputId": "e658f044-7a3f-4257-d4c6-1cb357333ef3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /content/interview_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Audio extracted and saved to /content/interview_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Speech-to-Text Transcript**"
      ],
      "metadata": {
        "id": "1MUAR9mP1yML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing necessary libraries\n",
        "!pip install SpeechRecognition moviepy pydub\n",
        "\n",
        "# Importing libraries\n",
        "import speech_recognition as sr\n",
        "from moviepy.editor import VideoFileClip\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to extract audio\n",
        "def extract_audio(video_path, output_audio_path):\n",
        "    clip = VideoFileClip(video_path)\n",
        "    clip.audio.write_audiofile(output_audio_path)\n",
        "    print(f\"Audio extracted to {output_audio_path}\")\n",
        "\n",
        "# Function to convert audio to proper format\n",
        "def convert_audio_to_wav(input_audio_path, output_audio_path):\n",
        "    audio = AudioSegment.from_file(input_audio_path)\n",
        "    audio = audio.set_channels(1)  # Mono-channel\n",
        "    audio = audio.set_frame_rate(16000)  # 16 kHz sample rate\n",
        "    audio.export(output_audio_path, format=\"wav\")\n",
        "    print(f\"Audio converted to WAV format: {output_audio_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Extracting audio from video\n",
        "video_path = \"/content/Adarsh_kumar_IITJODHPUR.mp4\"\n",
        "audio_path = \"/content/interview_audio.wav\"\n",
        "extract_audio(video_path, audio_path)\n",
        "\n",
        "# Step 2: Converting audio to proper format\n",
        "converted_audio_path = \"/content/interview_audio_converted.wav\"\n",
        "convert_audio_to_wav(audio_path, converted_audio_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6TAh8f6lyrZ",
        "outputId": "3de22b6e-378f-4c56-fe32-88f8fd6013aa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.11.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
            "MoviePy - Writing audio in /content/interview_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Audio extracted to /content/interview_audio.wav\n",
            "Audio converted to WAV format: /content/interview_audio_converted.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Analysis**"
      ],
      "metadata": {
        "id": "dT7mqRjW2Ayd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Step 1: Transcribe the audio\n",
        "def transcribe_audio(audio_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        print(\"Transcribing audio...\")\n",
        "        audio = recognizer.record(source)\n",
        "        try:\n",
        "            return recognizer.recognize_google(audio)\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Audio was unintelligible.\"\n",
        "        except sr.RequestError as e:\n",
        "            return f\"Error with speech recognition service: {e}\"\n",
        "\n",
        "# Step 2: Analyzing sentiment\n",
        "def analyze_sentiment(transcript):\n",
        "    blob = TextBlob(transcript)\n",
        "    sentiment_score = blob.sentiment.polarity  # -1 (negative) to 1 (positive)\n",
        "    print(\"\\n--- Sentiment Analysis ---\\n\")\n",
        "    if sentiment_score > 0:\n",
        "        print(\"Positive Sentiment\")\n",
        "    elif sentiment_score < 0:\n",
        "        print(\"Negative Sentiment\")\n",
        "    else:\n",
        "        print(\"Neutral Sentiment\")\n",
        "    print(f\"Sentiment Score: {sentiment_score}\")\n",
        "\n",
        "# Step 3: Process the audio file and run sentiment analysis\n",
        "audio_path = \"/content/interview_audio_converted.wav\"  # Ensure the path is correct\n",
        "transcript = transcribe_audio(audio_path)\n",
        "\n",
        "if transcript:\n",
        "    print(\"\\n--- Transcript ---\\n\")\n",
        "    print(transcript)\n",
        "    analyze_sentiment(transcript)\n",
        "else:\n",
        "    print(\"No transcript available to analyze sentiment.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wAf1JMQ1vdE",
        "outputId": "77f17c51-9d21-4e80-f69d-9df864d3d539"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing audio...\n",
            "\n",
            "--- Transcript ---\n",
            "\n",
            "Audio was unintelligible.\n",
            "\n",
            "--- Sentiment Analysis ---\n",
            "\n",
            "Neutral Sentiment\n",
            "Sentiment Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facial Expression Analysis (Optional)\n"
      ],
      "metadata": {
        "id": "k5G3xZN92ErG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # For displaying frames in Colab\n",
        "\n",
        "def analyze_facial_expressions(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    # Output video settings\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    output_path = \"/content/facial_expression_analysis_output.avi\"\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "        # Optional: Displaying the frame in Colab\n",
        "\n",
        "        # cv2_imshow(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Facial expression analysis completed. Processed video saved at {output_path}\")\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# Run the analysis\n",
        "processed_video_path = analyze_facial_expressions(\"/content/Adarsh_kumar_IITJODHPUR.mp4\")\n",
        "\n",
        "# Optional: Download the processed video\n",
        "from google.colab import files\n",
        "files.download(processed_video_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "3kWDecRB1vVq",
        "outputId": "7750e114-63b7-46ca-a9ee-5dae17ae892f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Facial expression analysis completed. Processed video saved at /content/facial_expression_analysis_output.avi\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1d072bfc-90a6-475d-933b-85004b88b50f\", \"facial_expression_analysis_output.avi\", 113473910)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Storing in Vector** **Database**"
      ],
      "metadata": {
        "id": "JjOSQzvL3UyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_P1KDK_L9Ek4sZAE42JHEMXwDmkhYdspNXCPgmMfCXobddU9zeepUKeDM9YwgZETkPXaQq\"  # Replace with your actual API key"
      ],
      "metadata": {
        "id": "zZvoM60M-jVQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"pcsk_P1KDK_L9Ek4sZAE42JHEMXwDmkhYdspNXCPgmMfCXobddU9zeepUKeDM9YwgZETkPXaQq\"  # Replace with your actual API key\n",
        "import os\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_P1KDK_L9Ek4sZAE42JHEMXwDmkhYdspNXCPgmMfCXobddU9zeepUKeDM9YwgZETkPXaQq\"  # Replace with your actual API key\n",
        "from pinecone import Pinecone\n",
        "\n",
        "# Test initialization with API key\n",
        "try:\n",
        "    pc = Pinecone(api_key=\"pcsk_P1KDK_L9Ek4sZAE42JHEMXwDmkhYdspNXCPgmMfCXobddU9zeepUKeDM9YwgZETkPXaQq\")\n",
        "    print(\"Pinecone initialized successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSLy7bDf60hP",
        "outputId": "7ae05c30-8a56-4fbf-cab0-a69309765769"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinecone initialized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Replace with your actual Pinecone API key\n",
        "pinecone_api_key = \"pcsk_P1KDK_L9Ek4sZAE42JHEMXwDmkhYdspNXCPgmMfCXobddU9zeepUKeDM9YwgZETkPXaQq\"\n",
        "\n",
        "# Initialize Pinecone client\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Index name for the interview analysis\n",
        "index_name = \"interview-analysis\"\n",
        "\n",
        "\n",
        "print(\"Existing indexes:\", pc.list_indexes())\n",
        "\n",
        "\n",
        "if index_name not in pc.list_indexes():\n",
        "    try:\n",
        "        pc.create_index(\n",
        "            name=index_name,\n",
        "            dimension=512,\n",
        "            metric=\"cosine\",\n",
        "            spec=ServerlessSpec(\n",
        "                cloud=\"aws\",\n",
        "                region=\"us-west-2\"\n",
        "            )\n",
        "        )\n",
        "        print(f\"Index '{index_name}' created successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during index creation: {e}\")\n",
        "else:\n",
        "    print(f\"Index '{index_name}' already exists.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy_De8yw_CA2",
        "outputId": "fda32127-fcef-4909-d4eb-f443f1cb340d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing indexes: {'indexes': []}\n",
            "Error during index creation: (400)\n",
            "Reason: Bad Request\n",
            "HTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '2d25772828da187c83b96abda98955bc', 'Date': 'Sun, 01 Dec 2024 06:55:13 GMT', 'Server': 'Google Frontend', 'Content-Length': '200', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
            "HTTP response body: {\"error\":{\"code\":\"INVALID_ARGUMENT\",\"message\":\"Bad request: Your free plan does not support indexes in the us-west-2 region of aws. To create indexes in this region, upgrade your plan.\"},\"status\":400}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RAG and Contextual Summary Generation**"
      ],
      "metadata": {
        "id": "47DJn_HK3zhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getenv(\"pcsk_6B4hDs_T9bxYYtAAp6AdEVBUwqDU3EDBFPFUgtzU1QnsA1TpTCLqMQR6qRJCyTPyiBk9tz\"))  # Replace with your actual environment variable name\n",
        "pc = Pinecone(api_key=\"pcsk_6B4hDs_T9bxYYtAAp6AdEVBUwqDU3EDBFPFUgtzU1QnsA1TpTCLqMQR6qRJCyTPyiBk9tz\")\n",
        "try:\n",
        "    indexes = pc.list_indexes()\n",
        "    print(\"Connected successfully. Available indexes:\", indexes)\n",
        "except Exception as e:\n",
        "    print(\"Error connecting to Pinecone:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhQDXYWXwYUW",
        "outputId": "5d2cf02c-3877-4e7a-9aa7-e21fb8682ae5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Connected successfully. Available indexes: {'indexes': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07BKySh0wYRT",
        "outputId": "7bc49cdf-caad-4d9e-a33c-51ed8c531318"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Communication Style:**"
      ],
      "metadata": {
        "id": "RZSimOmXxUeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CandidatePerformance:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.communication_style = \"\"\n",
        "        self.active_listening = \"\"\n",
        "        self.engagement = \"\"\n",
        "\n",
        "    def set_communication_style(self, clarity, effectiveness):\n",
        "        self.communication_style = f\"Communication Style: The candidate demonstrated clarity in expression by {clarity}. Their effectiveness was evident as they {effectiveness}.\"\n",
        "\n",
        "    def set_active_listening(self, attentiveness, responsiveness):\n",
        "        self.active_listening = f\"Active Listening: The candidate showed attentiveness by {attentiveness} and was responsive to questions by {responsiveness}.\"\n",
        "\n",
        "    def set_engagement(self, interaction_level, rapport):\n",
        "        self.engagement = f\"Engagement with the Interviewer: The candidate's level of interaction was {interaction_level}, and they established rapport by {rapport}.\"\n",
        "\n",
        "    def generate_summary(self):\n",
        "        return f\"Candidate Performance Summary for {self.name}:\\n\\n\" + \\\n",
        "               f\"{self.communication_style}\\n\\n\" + \\\n",
        "               f\"{self.active_listening}\\n\\n\" + \\\n",
        "               f\"{self.engagement}\\n\"\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    candidate = CandidatePerformance(\"John Doe\")\n",
        "\n",
        "    # Setting attributes based on my observations\n",
        "    candidate.set_communication_style(\n",
        "        clarity=\"articulating thoughts clearly and using appropriate terminology\",\n",
        "        effectiveness=\"summarized key points succinctly\"\n",
        "    )\n",
        "\n",
        "    candidate.set_active_listening(\n",
        "        attentiveness=\"maintaining eye contact and nodding in acknowledgment\",\n",
        "        responsiveness=\"referencing previous points made by the interviewer\"\n",
        "    )\n",
        "\n",
        "    candidate.set_engagement(\n",
        "        interaction_level=\"high, with insightful questions\",\n",
        "        rapport=\"demonstrating curiosity and genuine interest\"\n",
        "    )\n",
        "\n",
        "    # Generating and printing the summary\n",
        "    summary = candidate.generate_summary()\n",
        "    print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62J49rPOwYJ2",
        "outputId": "4c22c882-0293-4fac-ff11-551458d648d8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate Performance Summary for John Doe:\n",
            "\n",
            "Communication Style: The candidate demonstrated clarity in expression by articulating thoughts clearly and using appropriate terminology. Their effectiveness was evident as they summarized key points succinctly.\n",
            "\n",
            "Active Listening: The candidate showed attentiveness by maintaining eye contact and nodding in acknowledgment and was responsive to questions by referencing previous points made by the interviewer.\n",
            "\n",
            "Engagement with the Interviewer: The candidate's level of interaction was high, with insightful questions, and they established rapport by demonstrating curiosity and genuine interest.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Active Listening**:\n",
        "- **Engagement with the Interviewer**:"
      ],
      "metadata": {
        "id": "xk0OnOJlxX-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "class InterviewAnalysis:\n",
        "    def __init__(self, transcript):\n",
        "        self.transcript = transcript\n",
        "        self.active_listening_count = 0\n",
        "        self.engagement_count = 0\n",
        "\n",
        "    def analyze_active_listening(self):\n",
        "        # Keywords indicating active listening\n",
        "        active_listening_keywords = ['I see', 'That makes sense', 'So you are saying', 'In other words']\n",
        "        self.active_listening_count = sum(transcript.lower().count(keyword.lower()) for keyword in active_listening_keywords)\n",
        "\n",
        "    def analyze_engagement(self):\n",
        "        # Count questions asked by the candidate\n",
        "        questions = re.findall(r'\\b\\w+\\s+\\w+\\s*\\?\\s*', self.transcript)\n",
        "        self.engagement_count = len(questions)\n",
        "\n",
        "    def generate_report(self):\n",
        "        return f\"Active Listening Instances: {self.active_listening_count}\\n\" + \\\n",
        "               f\"Engagement Instances (Questions Asked): {self.engagement_count}\\n\"\n",
        "\n",
        "# Example\n",
        "if __name__ == \"__main__\":\n",
        "    interview_transcript = \"\"\"\n",
        "    Interviewer: Can you tell me about your experience with Python?\n",
        "    Candidate: I see, you want to know about my experience. In other words, I have worked on several projects using Python.\n",
        "    Interviewer: What kind of projects?\n",
        "    Candidate: That's interesting! I have worked on data analysis and web development. Can you tell me more about the team?\n",
        "    \"\"\"\n",
        "\n",
        "    analysis = InterviewAnalysis(interview_transcript)\n",
        "    analysis.analyze_active_listening()\n",
        "    analysis.analyze_engagement()\n",
        "\n",
        "    report = analysis.generate_report()\n",
        "    print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR-x-F1sxOd-",
        "outputId": "7f6539f0-88eb-440e-95f4-4458dfffaa09"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active Listening Instances: 0\n",
            "Engagement Instances (Questions Asked): 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vmrx2tTx4mQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}